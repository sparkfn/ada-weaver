# ─── GitHub ────────────────────────────────────────────────────────────────────
GITHUB_OWNER=your-github-username
GITHUB_REPO=your-repo-name

# Auth option 1: Personal Access Token
GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Auth option 2: GitHub App (comment out GITHUB_TOKEN above if using this)
# GITHUB_APP_ID=123456
# GITHUB_APP_PEM_PATH=/path/to/your/app.pem
# GITHUB_APP_INSTALLATION_ID=12345678

# ─── LLM (main model) ─────────────────────────────────────────────────────────
# Providers: anthropic, openai, openai-responses, openai-compatible, ollama
LLM_PROVIDER=anthropic
LLM_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
LLM_MODEL=claude-sonnet-4-20250514
# LLM_BASE_URL=                     # only needed for openai-compatible provider

# ─── Issuer LLM (optional — cheaper/faster model for issue understanding) ─────
# Omit these to use the main LLM. All-or-nothing: set PROVIDER to enable.
# Backward compat: TRIAGE_LLM_* env vars are also accepted.
# ISSUER_LLM_PROVIDER=anthropic
# ISSUER_LLM_API_KEY=sk-ant-xxx
# ISSUER_LLM_MODEL=claude-haiku-4-5-20251001
# ISSUER_LLM_BASE_URL=

# ─── Coder LLM (optional — different model for code implementation) ──────────
# Omit these to use the main LLM. All-or-nothing: set PROVIDER to enable.
# CODER_LLM_PROVIDER=anthropic
# CODER_LLM_API_KEY=sk-ant-xxx
# CODER_LLM_MODEL=claude-sonnet-4-20250514
# CODER_LLM_BASE_URL=

# ─── Reviewer LLM (optional — different model for PR reviews) ────────────────
# Omit these to use the main LLM for reviews. All-or-nothing: set PROVIDER to enable.
# REVIEWER_LLM_PROVIDER=anthropic
# REVIEWER_LLM_API_KEY=sk-ant-xxx
# REVIEWER_LLM_MODEL=claude-haiku-4-5-20251001
# REVIEWER_LLM_BASE_URL=

# ─── Server ───────────────────────────────────────────────────────────────────
# PORT=3000                          # unified server port for `deepagents serve`

# ─── Webhook ──────────────────────────────────────────────────────────────────
# Required for `pnpm webhook` and Docker deployment.
# WEBHOOK_PORT=3000
# WEBHOOK_SECRET=                    # generate with: openssl rand -hex 32

# ─── Limits ───────────────────────────────────────────────────────────────────
# MAX_ISSUES_PER_RUN=5               # cap issues processed per poll cycle
# MAX_TOOL_CALLS_PER_RUN=30          # circuit breaker — exits with code 2 when tripped
# MAX_ITERATIONS=3                   # max review→fix iterations per issue (backward compat: MAX_FEEDBACK_ITERATIONS)
# AGENT_MODE=multi                    # "multi" (default, Architect+3 subagents) or "single" (one agent, all tools, shared context)

# ─── Database (optional — enables persistent storage) ─────────────────────────
# Option 1: Connection URL (preferred for Docker/production)
# DATABASE_URL=postgresql://deepagents:password@localhost:5432/deepagents
#
# Option 2: Individual fields (for local dev)
# PG_HOST=localhost
# PG_PORT=5432
# PG_DATABASE=deepagents
# PG_USER=deepagents
# PG_PASSWORD=password

# ─── Bitrix24 Notifications (optional) ────────────────────────────────────────
# Connection details for Bitrix24 REST API. Toggles and dialog ID are configured
# in the dashboard Settings tab and saved to the database.
# BITRIX_BASE_URL=https://hq.ada.asia
# BITRIX_USER_ID=103726
# BITRIX_WEBHOOK_ID=your-webhook-id

# ─── Docker / Caddy (production deployment only) ─────────────────────────────
# DOMAIN=yourdomain.com              # used by Caddyfile for TLS
# CLOUDFLARE_API_TOKEN=your-cloudflare-api-token-here
